{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian generative models for handwritten digit classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that the 1-NN classifier yielded a 3.09% test error rate on the MNIST data set of handwritten digits. We will now see that a Gaussian generative model does almost as well, while being significantly faster and more compact."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Set up notebook and load in data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As usual, we start by importing the required packages and data. For this notebook we will be using the *entire* `MNIST` dataset. The code below defines some helper functions that will load `MNIST` onto your computer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import sys\n",
    "import matplotlib.pyplot as plt \n",
    "import gzip, os\n",
    "import numpy as np\n",
    "from scipy.stats import multivariate_normal\n",
    "\n",
    "if sys.version_info[0] == 2:\n",
    "    from urllib import urlretrieve\n",
    "else:\n",
    "    from urllib.request import urlretrieve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that downloads a specified MNIST data file from Yann Le Cun's website\n",
    "def download(filename, source='http://yann.lecun.com/exdb/mnist/'):\n",
    "    print(\"Downloading %s\" % filename)\n",
    "    urlretrieve(source + filename, filename)\n",
    "\n",
    "# Invokes download() if necessary, then reads in images\n",
    "def load_mnist_images(filename):\n",
    "    if not os.path.exists(filename):\n",
    "        download(filename)\n",
    "    with gzip.open(filename, 'rb') as f:\n",
    "        data = np.frombuffer(f.read(), np.uint8, offset=16)\n",
    "    data = data.reshape(-1,784)\n",
    "    return data\n",
    "\n",
    "def load_mnist_labels(filename):\n",
    "    if not os.path.exists(filename):\n",
    "        download(filename)\n",
    "    with gzip.open(filename, 'rb') as f:\n",
    "        data = np.frombuffer(f.read(), np.uint8, offset=8)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now load in the training set and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading train-images-idx3-ubyte.gz\n",
      "Downloading train-labels-idx1-ubyte.gz\n",
      "Downloading t10k-images-idx3-ubyte.gz\n",
      "Downloading t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "## Load the training set\n",
    "train_data = load_mnist_images('train-images-idx3-ubyte.gz')\n",
    "train_labels = load_mnist_labels('train-labels-idx1-ubyte.gz')\n",
    "\n",
    "## Load the testing set\n",
    "test_data = load_mnist_images('t10k-images-idx3-ubyte.gz')\n",
    "test_labels = load_mnist_labels('t10k-labels-idx1-ubyte.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function **displaychar** shows a single MNIST digit. To do this, it first has to reshape the 784-dimensional vector into a 28x28 image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def displaychar(image):\n",
    "    plt.imshow(np.reshape(image, (28,28)), cmap=plt.cm.gray)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displaychar(train_data[58])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training set consists of 60,000 images. Thus `train_data` should be a 60000x784 array while `train_labels` should be 60000x1. Let's check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 784), (60000,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape, train_labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Fit a Gaussian generative model to the training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color=\"magenta\">For you to do:</font>** Define a function, **fit_generative_model**, that takes as input a training set (data `x` and labels `y`) and fits a Gaussian generative model to it. It should return the parameters of this generative model; for each label `j = 0,1,...,9`, we have:\n",
    "* `pi[j]`: the frequency of that label\n",
    "* `mu[j]`: the 784-dimensional mean vector\n",
    "* `sigma[j]`: the 784x784 covariance matrix\n",
    "\n",
    "This means that `pi` is 10x1, `mu` is 10x784, and `sigma` is 10x784x784.\n",
    "\n",
    "We have already seen how to fit a Gaussian generative model in the Winery example, but now there is an added ingredient. <font color=\"magenta\">The empirical covariances are very likely to be singular (or close to singular), which means that we won't be able to do calculations with them</font>. Thus it is important to **regularize** these matrices. The standard way of doing this is to add `cI` to them, where `c` is some constant and `I` is the 784-dimensional identity matrix. (To put it another way, we compute the empirical covariances and then increase their diagonal entries by some constant `c`.)\n",
    "\n",
    "This modification is guaranteed to yield covariance matrices that are non-singular, for any `c > 0`, no matter how small. But this doesn't mean that we should make `c` as small as possible. Indeed, `c` is now a parameter, and by setting it appropriately, we can improve the performance of the model. We will study **regularization** in greater detail over the coming weeks.\n",
    "\n",
    "Your routine needs to choose a good setting of `c`. Crucially, this needs to be done using the training set alone. So you might try setting aside part of the training set as a validation set, or using some kind of cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_generative_model(x,y):\n",
    "    k = 10  # labels 0,1,...,k-1\n",
    "    d = (x.shape)[1]  # number of features\n",
    "    mu = np.zeros((k,d))\n",
    "    sigma = np.zeros((k,d,d))\n",
    "    pi = np.zeros(k)\n",
    "    ###\n",
    "    ### Your code goes here        \n",
    "    \n",
    "    for label in range(0,k):\n",
    "        indices = (y == label)\n",
    "        mu[label] = np.mean(x[indices,:], axis=0)\n",
    "        sigma[label] = np.cov(x[indices,:], rowvar=0, bias=1)\n",
    "        pi[label] = float(sum(indices))/float(len(y))\n",
    "    \n",
    "    # Halt and return parameters\n",
    "    return mu, sigma, pi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, let's try out your function. In particular, we will use **displaychar** to visualize the means of the Gaussians for the first three digits. You can try the other digits on your own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAGFCAYAAAASI+9IAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAANI0lEQVR4nO3cXXfNZ9fG4blEiJfGS6JKlNLhpdX2+3+OtqiBlluERNGQCCJZz9659WyY1xjN7Zbj2HaOtays+PW/0TmZTqfTAoCqOvDffgMAfD5EAYAQBQBCFAAIUQAgRAGAEAUAQhQAiIOf+gcnk8m/+T4A+Jd9yv+r7EkBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAIiD/+03wP4xmUz2bPc5b0ZNp9M92YzYy/e2V3+n/cqTAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAEA4iPeFGTnQNjMz097Mzs62N3Nzc+1NVdWJEyfam9OnT+/J64xsDh4c+7V7//59e/P69ev25sWLF+3Nq1ev2puR91ZV9e7du/bm48eP7c1+PbznSQGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgHMT7TB04MNbrkWNrR44caW9GDsGdO3euvamqunz5cntz7dq1PXmds2fPtjejhwE3Njbam+Xl5fbm3r177c2dO3fam4cPH7Y3VVWrq6vtzZs3b9qbkSN6XwJPCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgDhIN4eGDluN3LYrmrsuN3i4mJ7c/Hixfbmxo0b7U1V1U8//bQnrzXyd1pYWGhvZmdn25uqsQNta2tr7c3S0lJ7M3Ig8fDhw+1NVdXu7m57s7293d5sbm62N9PptL353HhSACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAgH8Zomk0l7M3IQb/RY2KlTp9qbkUNwN2/ebG9++eWX9qaq6vr16+3NyFG3+fn59mbk+zBy0K1q7Eji119/3d6MHHXb2dlpb969e9feVI0dqtvY2GhvRt7fyNHCz40nBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQDCldSmkauYs7Oz7c1XX33V3lRVnT9/vr25evVqe/Pjjz/uyetU7d2lz9XV1fZm5GLn9vZ2e1M19j0aufw6cqF35NLuP//8095UVT1//ry9efr0aXvz6tWr9saVVAC+KKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhIN4TQcO9Ds6NzfX3pw5c6a9qaq6dOlSe3P9+vX25vvvv29vFhYW2puqsSNja2tr7c3y8nJ7M3JE782bN+1N1dihuqWlpfZm5Gd7/Pjx9mbkeGPV2PG9+/fvtzePHz9ub7a2ttqbz40nBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYBwEK9pdna2vTlx4kR7M3osbOSY2ZUrV9qb0YN9I54+fdre3L17t70ZOZr2n//8p73Z3Nxsb6qqjhw50t6M/GxHjBxVnJ+fH3qtc+fOtTeLi4vtzcgBwi+BJwUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGA2NcH8SaTSXszciRrYWGhvbl48WJ7UzV2AG3kwNjIYcDV1dX2pqrq1q1b7c2vv/7a3jx48KC9WVtba28+fPjQ3lRVHT9+vL0Z+Y6PfB+Wlpbam9GDeCMHJk+dOtXezM3NtTdfAk8KAIQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAMS+vpJ64EC/iSOXKkeuTl6+fLm9qaq6cOFCe3Ps2LH2ZmNjo725f/9+e1M1dvF05LLqyspKe/P27dv2ZjqdtjdVVR8/fmxv1tfX25tXr161N5ubm+3NyO9S1diF3qNHj7Y3hw4dam++BJ4UAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAGJfH8SbmZlpb06ePNneLC0ttTcXL15sb6qqFhYW2pvd3d32Znl5ub25fft2e1NVdefOnfbm8ePH7c2bN2/am5EjdSOHGKuq5ubm2pudnZ092Yx8DiPfu6qxg4Ijn/nBg/1/HieTSXtTNX4k8d/gSQGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAg9vVBvJGDVyMH50YO4n3zzTftTVXV0aNH25vnz5+3N3/99Vd7c+/evfamqmplZaW9GTlu9+HDh/Zm5JDZ6NG0kQOOhw8fbm+OHDnS3oz8Lo0c3quqev/+/Z5sPqcjdXvJkwIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBA7OuDeCPHwhYXF9ubkeN2J06caG+qqnZ3d9ubvTqI9+TJk/amqur169ftzchxu5EDbQcO9P+7anZ2tr2pqpqfn29vRr6vp0+fbm/m5ubam5EjdVVjxw43Njbam5Hv0JfAkwIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBA7OuDeIcOHWpvTp061d6cPHmyvRk5MFY1dmRs5CDes2fP2puRw3ZVVdvb2+3NyGHAkeN2I0cVR74PVVXnz59vby5dutTenDt3rr0Z+V1aX19vb6qq1tbW2puXL1+2N+/evWtvvgSeFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFACIfX0ldeTC5dGjR9ubkYunIxc7q8aupG5ubrY3W1tb7c3Ozk57U1U1mUzam9nZ2fZm5NLnyMXTkculVVU//PBDe3Pt2rX2ZnFxsb0ZuUo7cp23qmplZaW9WV1dbW9GvuPT6bS9+dx4UgAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFACIfX0Qb+To3MjBq708kjUzM9PejByCO378eHszPz/f3lSNfX4jP9uR9/ftt9+2Nzdu3Ghvqqp+/vnn9ua7775rb0YOOD59+rS9efToUXtTVfX48eP25u+//25vRo5Lfgk8KQAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgDEvj6It7u72968ffu2vdna2mpvRt5b1dihupGjbtevX29vJpNJe1NVtbGx0d6MHPk7e/ZsezNycO7q1avtTVXV0tJSezPyOayurrY3Dx482JNN1dhBvPX19fZme3u7vfkSeFIAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQAiH19EO/9+/ftzfPnz9ubtbW19mbkCFxV1fnz59ubmzdvtjfz8/PtzcgRvaq9O4h3+vTp9mbkiN7IZ1dVNZ1O25uVlZX25u7du+3N7du325t79+61N1VVz549a282Nzfbm9GjlP/rPCkAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAxL4+iPf27dv25smTJ+3NyOGvc+fOtTdVY0fdlpaW2ptvv/22vdna2mpvRnc7OzvtzczMTHszcqTu5cuX7U1V1aNHj9qbW7dutTe///57e/PHH3+0N8vLy+1NVdX6+np78/Hjx/Zm5Gf7JfCkAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAEDs6yup7969a29WVlbam99++629OXToUHszand3t725cOFCe3Py5Mn2pqrqxIkT7c3Iz/bFixftzePHj9ubu3fvtjdVYxdP79y50948fPiwvXn27Fl7s7Gx0d5UVW1vb7c3I9/x/cqTAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAEBMptPp9JP+4GTyb7+XPTfydxo5VDdy0G3k4FxV1bVr19qbGzdutDdXrlxpb86cOdPeVFXNzMy0N+vr6+3NkydP2ps///xzTzZVY8f31tbW2pvXr1+3N+/fv29vdnZ22puqqk/8J4v/x6d8dp4UAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAGJfH8TbKwcO9Ns7Ozs79Fpzc3PtzbFjx9qbo0ePtjcj761q7PMbOba2tbXV3rx9+3ZPXqdq7Ojc9vZ2e7O7u9veOFL3v8FBPABaRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIB/EA9gkH8QBoEQUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQAiIOf+gen0+m/+T4A+Ax4UgAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACD+DwqhnJTawz1PAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mu, sigma, pi = fit_generative_model(train_data, train_labels)\n",
    "displaychar(mu[0])\n",
    "displaychar(mu[1])\n",
    "displaychar(mu[2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Make predictions on test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see how many errors your model makes on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now test the performance of a predictor based on a subset of features\n",
    "def test_model(mu, sigma, pi, tx, ty):\n",
    "    # to do code here\n",
    "    k = 10\n",
    "    score = np.zeros((tx.shape[0] , k))\n",
    "    for label in range(0,k):\n",
    "        score[: , label] = np.log(pi[label]) + multivariate_normal.logpdf(tx, mean=mu[label], cov=sigma[label])\n",
    "       \n",
    "    predictions = np.argmax(score[:,:], axis=1)\n",
    "    errors = np.sum(predictions != ty)\n",
    "    return errors\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your model makes 1866 errors out of 10000\n",
      "This is 18.66% error rate\n"
     ]
    }
   ],
   "source": [
    "errors = test_model(mu, sigma, pi, test_data, test_labels)\n",
    "print(\"Your model makes \" + str(errors) + \" errors out of 10000\")\n",
    "print(\"This is \" + str(errors/100) + \"% error rate\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  choose C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- use cross validation and tunning to search about good c value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = np.identity(784) * 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainx , valx , trainy , valy = train_test_split(train_data,train_labels,stratify=train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu, sigma, pi = fit_generative_model(trainx, trainy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best validation score: 7.07\n",
      "best c: 2824\n"
     ]
    }
   ],
   "source": [
    "# tunning for best c depend on small validation set\n",
    "\n",
    "val_scores = []\n",
    "\n",
    "c = np.arange(2820, 2840, 2)\n",
    "for i in c:\n",
    "    new_sigma = 0 \n",
    "    new_sigma = ( np.identity(784) * i ) + sigma\n",
    "    error_score = test_model(mu, new_sigma, pi, valx, valy) / 100 \n",
    "    val_scores.append(error_score)\n",
    "print(f\"best validation score: {np.min(val_scores):.3}\")\n",
    "best_c = c[np.argmin(val_scores)]\n",
    "print(\"best c:\", best_c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7.08, 7.08, 7.07, 7.07, 7.07, 7.07, 7.07, 7.07, 7.07, 7.07]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24.4\n"
     ]
    }
   ],
   "source": [
    "# error in train\n",
    "mu, sigma, pi = fit_generative_model(train_data, train_labels)\n",
    "new_sigma = ( np.identity(784) * 2830 ) + sigma\n",
    "error_score = test_model(mu, new_sigma, pi, train_data,train_labels) / 100 \n",
    "print(error_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.28\n"
     ]
    }
   ],
   "source": [
    "error_score = test_model(mu, new_sigma, pi, test_data,test_labels) / 100 \n",
    "print(error_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Quick exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*You will need to answer variants of these questions as part of this week's assignment*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"magenta\">Exercise 1:</font> What happens if you do not regularize the covariance matrices?\n",
    "- linera algebra error, get singular matrix, if we allow singlar the error rate is 18.66"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"magenta\">Exercise 2:</font> What happens if you set the value of `c` too high, for instance to one billion? Do you understand why this happens?\n",
    "- the error rate increase , no"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"magenta\">Exercise 3:</font> What value of c did you end up using? How many errors did your model make on the training set?\n",
    "- c = 2830 , 24.18 and 4.27 in the testset !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"magenta\">If you have the time</font>: We have talked about using the same regularization constant `c` for all ten classes. What about using a different value of `c` for each class? How would you go about choosing these? Can you get better performance in this way?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### what if using different c for every class ? and what this Cs ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- i think we need only to change sigma by label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu, sigma, pi = fit_generative_model(trainx, trainy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{13.34: [2838, 2613, 2930, 2852, 2899, 2704, 2875, 2868, 2911, 2724], 12.15: [2758, 2717, 2901, 2841, 2772, 2834, 2556, 2947, 2852, 2993], 16.2: [2752, 2953, 2928, 2537, 2983, 2611, 2885, 2529, 2709, 2587], 14.25: [2619, 2903, 2849, 2754, 2822, 2617, 2912, 2731, 2523, 2974], 15.85: [2728, 2898, 2688, 2782, 2607, 2500, 2567, 2968, 2726, 2966], 27.33: [2732, 2868, 2980, 2772, 2800, 2505, 2663, 2879, 2788, 2513], 23.69: [2768, 2626, 2621, 2622, 2834, 2763, 2968, 2725, 2658, 2806], 26.29: [2984, 2730, 2711, 2811, 2929, 2763, 2535, 2752, 2971, 2985], 26.41: [2753, 2865, 2805, 2898, 2860, 2937, 2572, 2985, 2904, 2554], 32.11: [2984, 2662, 2642, 2791, 2876, 2549, 2787, 2687, 2559, 2904], 31.78: [2821, 2817, 2623, 2854, 2867, 2870, 2600, 2807, 2722, 2609], 40.7: [2943, 2575, 2737, 2918, 2876, 2700, 2549, 2781, 2873, 2855], 47.04: [2700, 2934, 2699, 2751, 2721, 2515, 2988, 2614, 2905, 2640], 50.12: [2808, 2556, 2923, 2662, 2955, 2802, 2664, 2810, 2859, 2620], 54.4: [2861, 2759, 2629, 2910, 2615, 2783, 2559, 2852, 2901, 2616], 52.96: [2589, 2619, 2785, 2578, 2621, 2694, 2586, 2782, 2895, 2980], 47.52: [2630, 2942, 2825, 2903, 2595, 2999, 2759, 2534, 2887, 2565], 41.63: [2708, 2889, 2684, 2619, 2611, 2898, 2829, 2532, 2956, 2592], 38.29: [2782, 2646, 2751, 2604, 2727, 2661, 2956, 2783, 2994, 2921], 45.89: [2617, 2592, 2775, 2687, 2927, 2666, 2595, 2964, 2814, 2633], 49.33: [2926, 2840, 2559, 2879, 2848, 2606, 2570, 2770, 2831, 2966], 51.96: [2824, 2670, 2991, 2645, 2870, 2763, 2885, 2857, 2527, 2598], 61.46: [2983, 2580, 2662, 2960, 2880, 2504, 2974, 2759, 2643, 2697], 60.92: [2801, 2998, 2717, 2650, 2781, 2880, 2596, 2993, 2500, 2524], 69.65: [2888, 2774, 2853, 2802, 2985, 2537, 2811, 2895, 2947, 2737], 69.78: [2591, 2525, 2724, 2918, 2943, 2677, 2808, 2684, 2820, 2911], 64.88: [2988, 2769, 2670, 2525, 2835, 2925, 2733, 2522, 2809, 2519], 61.79: [2542, 2623, 2899, 2894, 2673, 2978, 2889, 2617, 2764, 2648], 63.03: [2979, 2707, 2560, 2639, 2538, 2702, 2694, 2641, 2771, 2578], 70.1: [2958, 2980, 2924, 2949, 2880, 2583, 2954, 2896, 2972, 2826], 63.94: [2580, 2930, 2728, 2611, 2950, 2963, 2657, 2698, 2508, 2620], 57.97: [2711, 2651, 2719, 2558, 2697, 2972, 2611, 2693, 2806, 2804], 59.82: [2902, 2665, 2533, 2655, 2639, 2893, 2803, 2926, 2576, 2600], 65.84: [2914, 2569, 2816, 2799, 2966, 2985, 2994, 2751, 2667, 2507], 62.87: [2857, 2947, 2816, 2773, 2544, 2602, 2797, 2700, 2916, 2918], 57.42: [2617, 2803, 2590, 2967, 2977, 2966, 2824, 2615, 2513, 2880], 56.34: [2550, 2720, 2578, 2566, 2894, 2713, 2607, 2726, 2898, 2712], 52.86: [2667, 2905, 2789, 2622, 2527, 2960, 2845, 2572, 2558, 2776], 51.49: [2928, 2591, 2525, 2885, 2761, 2963, 2651, 2775, 2792, 2980], 53.73: [2578, 2971, 2914, 2625, 2543, 2893, 2879, 2958, 2678, 2694], 56.09: [2943, 2834, 2754, 2910, 2685, 2885, 2614, 2745, 2684, 2705], 55.59: [2726, 2503, 2695, 2792, 2893, 2540, 2578, 2767, 2633, 2754], 59.15: [2519, 2556, 2946, 2854, 2629, 2640, 2525, 2763, 2787, 2693], 63.36: [2819, 2619, 2514, 2880, 2939, 2852, 2594, 2588, 2770, 2602], 60.07: [2642, 2687, 2705, 2889, 2811, 2719, 2724, 2558, 2865, 2886], 58.67: [2551, 2512, 2827, 2742, 2953, 2864, 2693, 2541, 2587, 2879], 56.64: [2964, 2572, 2756, 2608, 2928, 2570, 2729, 2612, 2594, 2933], 56.63: [2773, 2946, 2720, 2792, 2943, 2663, 2691, 2966, 2953, 2994], 59.19: [2977, 2720, 2739, 2969, 2786, 2956, 2989, 2865, 2801, 2861], 63.88: [2742, 2535, 2736, 2735, 2712, 2749, 2955, 2698, 2989, 2988], 69.4: [2731, 2566, 2943, 2799, 2513, 2611, 2517, 2577, 2781, 2891], 71.5: [2503, 2585, 2628, 2622, 2587, 2802, 2974, 2775, 2818, 2699], 78.8: [2826, 2556, 2983, 2794, 2523, 2954, 2633, 2696, 2785, 2913], 81.48: [2934, 2707, 2856, 2774, 2968, 2701, 2731, 2770, 2706, 2874], 80.09: [2619, 2916, 2543, 2685, 2986, 2815, 2985, 2579, 2917, 2987], 83.64: [2622, 2530, 2559, 2658, 2550, 2629, 2585, 2615, 2937, 2920], 84.27: [2911, 2718, 2513, 2990, 2967, 2652, 2744, 2587, 2996, 2532], 84.43: [2570, 2721, 2625, 2688, 2667, 2897, 2824, 2580, 2854, 2726], 84.98: [2602, 2639, 2672, 2748, 2670, 2645, 2582, 2709, 2832, 2712], 88.41: [2801, 2657, 2874, 2851, 2848, 2887, 2942, 2614, 2885, 2743], 88.23: [2655, 2729, 2819, 2579, 2904, 2521, 2935, 2774, 2700, 2941], 89.56: [2753, 2701, 2549, 2959, 2733, 2610, 2811, 2850, 2607, 2942], 93.96: [2923, 2567, 2709, 2854, 2860, 2941, 2796, 2826, 2647, 2572], 97.03: [2637, 2681, 2961, 2992, 2800, 2903, 2856, 2853, 2512, 2762], 95.97: [2739, 2793, 2618, 2897, 2868, 2689, 2624, 2896, 2684, 2762], 98.08: [2928, 2677, 2958, 2661, 2862, 2706, 2541, 2852, 2921, 2867], 101.48: [2574, 2528, 2844, 2552, 2879, 2983, 2661, 2924, 2647, 2512], 98.32: [2782, 2974, 2653, 2559, 2626, 2833, 2877, 2765, 2858, 2857], 94.66: [2612, 2833, 2523, 2705, 2735, 2641, 2655, 2681, 2880, 2621], 97.56: [2772, 2609, 2723, 2622, 2834, 2836, 2733, 2732, 2530, 2831], 101.83: [2918, 2581, 2547, 2785, 2850, 2978, 2899, 2917, 2562, 2968], 99.62: [2745, 2864, 2831, 2998, 2633, 2835, 2569, 2645, 2610, 2531], 95.26: [2964, 2985, 2641, 2678, 2970, 2823, 2581, 2691, 2690, 2656], 95.64: [2899, 2792, 2585, 2932, 2902, 2925, 2775, 2863, 2664, 2791], 97.02: [2638, 2551, 2503, 2589, 2880, 2805, 2862, 2641, 2507, 2502], 92.9: [2604, 2995, 2541, 2759, 2611, 2873, 2862, 2958, 2557, 2835], 92.02: [2960, 2871, 2572, 2864, 2547, 2880, 2633, 2793, 2827, 2707], 89.16: [2952, 2947, 2503, 2815, 2986, 2527, 2836, 2555, 2732, 2521], 92.52: [2506, 2528, 2511, 2821, 2799, 2862, 2985, 2564, 2518, 2616], 92.29: [2607, 2910, 2599, 2826, 2556, 2755, 2601, 2918, 2897, 2984], 87.56: [2792, 2993, 2947, 2589, 2899, 2531, 2697, 2921, 2570, 2872], 90.62: [2693, 2628, 2607, 2691, 2723, 2881, 2786, 2653, 2654, 2802], 88.54: [2532, 2542, 2996, 2649, 2765, 2800, 2533, 2557, 2613, 2618], 88.65: [2839, 2740, 2803, 2712, 2513, 2920, 2528, 2812, 2998, 2676], 89.61: [2518, 2548, 2766, 2628, 2948, 2711, 2860, 2509, 2807, 2515], 89.24: [2934, 2732, 2909, 2587, 2837, 2503, 2929, 2583, 2718, 2627], 85.58: [2636, 2982, 2742, 2823, 2622, 2520, 2983, 2778, 2918, 2702], 88.69: [2910, 2770, 2542, 2644, 2596, 2850, 2728, 2565, 2982, 2877], 92.15: [2942, 2725, 2936, 2962, 2896, 2930, 2990, 2557, 2567, 2899], 90.93: [2714, 2961, 2608, 2890, 2865, 2679, 2648, 2623, 2531, 2934], 89.62: [2633, 2783, 2678, 2983, 2692, 2817, 2566, 2839, 2602, 2645], 89.83: [2940, 2565, 2892, 2596, 2890, 2929, 2540, 2765, 2548, 2863], 87.19: [2520, 2924, 2659, 2637, 2726, 2890, 2943, 2632, 2636, 2664], 83.65: [2948, 2969, 2775, 2639, 2945, 2637, 2615, 2831, 2526, 2816], 78.48: [2631, 2930, 2876, 2863, 2574, 2607, 2585, 2783, 2751, 2593], 78.77: [2727, 2646, 2882, 2947, 2849, 2805, 2554, 2976, 2833, 2790], 78.9: [2896, 2673, 2829, 2661, 2559, 2853, 2883, 2718, 2558, 2646], 79.22: [2825, 2734, 2786, 2720, 2997, 2559, 2629, 2541, 2687, 2701]}\n"
     ]
    }
   ],
   "source": [
    "# tunning for best c depend on small validation set\n",
    "n_sigma = sigma.copy()\n",
    "val_scores = {}\n",
    "\n",
    "for ite in range(100) :\n",
    "    # fast test, take random numbers for 100 times\n",
    "    Cs = random.sample(range(2500, 3000 ), 10)\n",
    "    i = 0 \n",
    "    for c_label in Cs:\n",
    "        n_sigma[i] = n_sigma[i] + ( np.identity(784) * c_label ) \n",
    "        i = i + 1\n",
    "    error_score = test_model(mu, n_sigma, pi, valx, valy) / 100 \n",
    "    val_scores[error_score] = Cs\n",
    "  #  val_scores.append(error_score)\n",
    "    \n",
    "#print(f\"best validation score: {np.min(val_scores):.3}\")\n",
    "#best_Cs = c[np.argmin(val_scores)]\n",
    "#print(\"best c:\", best_c)\n",
    "print(val_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10,)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[2830.,    0.,    0., ...,    0.,    0.,    0.],\n",
       "        [   0., 2830.,    0., ...,    0.,    0.,    0.],\n",
       "        [   0.,    0., 2830., ...,    0.,    0.,    0.],\n",
       "        ...,\n",
       "        [   0.,    0.,    0., ..., 2830.,    0.,    0.],\n",
       "        [   0.,    0.,    0., ...,    0., 2830.,    0.],\n",
       "        [   0.,    0.,    0., ...,    0.,    0., 2830.]],\n",
       "\n",
       "       [[2830.,    0.,    0., ...,    0.,    0.,    0.],\n",
       "        [   0., 2830.,    0., ...,    0.,    0.,    0.],\n",
       "        [   0.,    0., 2830., ...,    0.,    0.,    0.],\n",
       "        ...,\n",
       "        [   0.,    0.,    0., ..., 2830.,    0.,    0.],\n",
       "        [   0.,    0.,    0., ...,    0., 2830.,    0.],\n",
       "        [   0.,    0.,    0., ...,    0.,    0., 2830.]],\n",
       "\n",
       "       [[2830.,    0.,    0., ...,    0.,    0.,    0.],\n",
       "        [   0., 2830.,    0., ...,    0.,    0.,    0.],\n",
       "        [   0.,    0., 2830., ...,    0.,    0.,    0.],\n",
       "        ...,\n",
       "        [   0.,    0.,    0., ..., 2830.,    0.,    0.],\n",
       "        [   0.,    0.,    0., ...,    0., 2830.,    0.],\n",
       "        [   0.,    0.,    0., ...,    0.,    0., 2830.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[2830.,    0.,    0., ...,    0.,    0.,    0.],\n",
       "        [   0., 2830.,    0., ...,    0.,    0.,    0.],\n",
       "        [   0.,    0., 2830., ...,    0.,    0.,    0.],\n",
       "        ...,\n",
       "        [   0.,    0.,    0., ..., 2830.,    0.,    0.],\n",
       "        [   0.,    0.,    0., ...,    0., 2830.,    0.],\n",
       "        [   0.,    0.,    0., ...,    0.,    0., 2830.]],\n",
       "\n",
       "       [[2830.,    0.,    0., ...,    0.,    0.,    0.],\n",
       "        [   0., 2830.,    0., ...,    0.,    0.,    0.],\n",
       "        [   0.,    0., 2830., ...,    0.,    0.,    0.],\n",
       "        ...,\n",
       "        [   0.,    0.,    0., ..., 2830.,    0.,    0.],\n",
       "        [   0.,    0.,    0., ...,    0., 2830.,    0.],\n",
       "        [   0.,    0.,    0., ...,    0.,    0., 2830.]],\n",
       "\n",
       "       [[2830.,    0.,    0., ...,    0.,    0.,    0.],\n",
       "        [   0., 2830.,    0., ...,    0.,    0.,    0.],\n",
       "        [   0.,    0., 2830., ...,    0.,    0.,    0.],\n",
       "        ...,\n",
       "        [   0.,    0.,    0., ..., 2830.,    0.,    0.],\n",
       "        [   0.,    0.,    0., ...,    0., 2830.,    0.],\n",
       "        [   0.,    0.,    0., ...,    0.,    0., 2830.]]])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "12px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": false,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
